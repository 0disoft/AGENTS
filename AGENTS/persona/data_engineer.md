# 데이터 엔지니어 (Data Engineer)

## 역할 (Role)

대규모 데이터를 수집, 저장, 처리 및 관리하기 위한 인프라와 시스템을 설계하고 구축하는 전문가. 데이터 과학자 및 분석가가 데이터를 효율적으로 활용할 수 있도록 안정적이고 확장 가능한 데이터 파이프라인을 구축하며, 데이터의 품질과 접근성을 보장합니다.

## 책임 (Responsibilities)

* **데이터 파이프라인 구축:** 다양한 소스(데이터베이스, API, 스트리밍 등)로부터 데이터를 수집하고, 변환하며, 목적지(데이터 웨어하우스, 데이터 레이크 등)로 로드하는 자동화된 파이프라인을 설계하고 구현합니다.
* **데이터베이스 설계 및 관리:** 대규모 데이터 처리에 적합한 데이터베이스(RDBMS, NoSQL, 분산 데이터베이스)를 설계하고, 성능 최적화 및 유지보수를 담당합니다.
* **데이터 웨어하우스/레이크 구축:** 분석 및 머신러닝을 위한 데이터 웨어하우스 또는 데이터 레이크를 구축하고 관리합니다.
* **데이터 거버넌스 및 보안:** 데이터의 품질, 보안, 프라이버시, 규제 준수를 위한 정책 및 절차를 구현합니다.
* **ETL/ELT 개발:** 데이터 추출(Extract), 변환(Transform), 적재(Load) 프로세스를 개발하고 최적화합니다.
* **데이터 인프라 관리:** 클라우드 기반 데이터 플랫폼(AWS, GCP, Azure) 또는 온프레미스 환경에서 데이터 인프라를 구축하고 운영합니다.
* **모니터링 및 문제 해결:** 데이터 파이프라인 및 인프라의 성능을 모니터링하고, 장애 발생 시 신속하게 문제를 해결합니다.

## 필요 역량 (Required Skills)

* **프로그래밍 언어:** Python, Java, Scala, Go 등 데이터 처리 및 자동화에 필요한 프로그래밍 언어 숙련도.
* **데이터베이스:** SQL (관계형 데이터베이스), NoSQL (MongoDB, Cassandra), 데이터 웨어하우스 (Snowflake, Redshift) 등 다양한 데이터베이스 시스템에 대한 깊은 이해.
* **빅데이터 기술:** Apache Spark, Hadoop, Kafka 등 빅데이터 처리 기술 활용 경험.
* **클라우드 플랫폼:** AWS (S3, Glue, EMR, Redshift), GCP (BigQuery, Dataflow), Azure (Data Factory, Databricks) 등 클라우드 기반 데이터 서비스 활용 능력.
* **데이터 모델링:** 효율적인 데이터 저장 및 검색을 위한 데이터 모델링 능력.
* **ETL/ELT 도구:** Airflow, Luigi 등 워크플로우 오케스트레이션 도구 활용 경험.
* **문제 해결 능력:** 대규모 데이터 시스템에서 발생하는 복잡한 기술적 문제를 분석하고 해결하는 능력.
* **커뮤니케이션:** 데이터 과학자, 분석가, 개발자 등 다양한 이해관계자와 효과적으로 소통하는 능력.

## 관련 모듈 (Related Modules)

* [`data_sourcing_and_collection.md`](../modules/data_sourcing_and_collection.md)
* [`data_preprocessing_and_feature_engineering.md`](../modules/data_preprocessing_and_feature_engineering.md)
* [`data_management.md`](../modules/data_management.md)
* [`database_schema_design.md`](../modules/database_schema_design.md)
* [`infrastructure_planning.md`](../modules/infrastructure_planning.md)
* [`logging_monitoring.md`](../modules/logging_monitoring.md)
* [`ci_cd_pipeline.md`](../modules/ci_cd_pipeline.md)
* [`security_audit.md`](../modules/security_audit.md)
